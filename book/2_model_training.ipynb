{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Implementing the model and training pipeline\n",
    "\n",
    "### Outline\n",
    "\n",
    "* Imports, including the library code from previous step\n",
    "* Description of LSTM-based models (describe modeling approach: seq2val)\n",
    "* Defining the training loop and procedure\n",
    "* Setting hyperparameters and region of interest\n",
    "* Running the model training\n",
    "* Recording model configuration and saving the trained model\n",
    "* Putting the model architecture code into a library module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and configuration\n",
    "\n",
    "Before we get to the core of the tutorial, actually building and training a neural network, we need to do all of the normal setup. This includes a standard set of imports, but also includes our first import from the local codebase which is in the `src` folder. Here we are going to import some functions from the `src.datapipes` module, which contains the key portions of the code from the previous tutorial on actually loading in the data. By offloading this to code in a python module we can make the actual content of this step of the tutorial much clearer. Additionally, this gives us a start of a python package that might be useful to others and could be adapted to be generally importable. Finally, after our imports we set the default `DEVICE` to use a GPU if it is available, and fall back to CPU if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1670556560147
    },
    "id": "EyDDFpFn7z9o"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Code from the last part of the tutorial!!\n",
    "from src.datapipes import make_data_pipeline, merge_data, select_region\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data pipeline\n",
    "\n",
    "If you followed along with the previous section of the tutorial you know the general pieces of info that go into setting up the data pipeline for our dataset, which culminated in developing the `make_data_pipeline` function. Before fully defining the pipelines, let's define our train/valid/test split. There are many ways to do this, and it's one of the most important parts of a rigorous machine learning pipeline. In our case, we'll just use a temporal split to define this, but our workflow is already set up quite nicely to use different regions for the splitting mechanism. Anyhow, for the tutorial we just set the splits as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1670557797268
    },
    "id": "I3CoB3HW8QdX",
    "outputId": "9f7a7817-bfd4-48ca-e22c-adbee29846b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_period = slice('1985', '2000')\n",
    "valid_period = slice('2001', '2007')\n",
    "test_period = slice('2008', '2015')\n",
    "\n",
    "ds = merge_data()\n",
    "train_ds = ds.sel(time=train_period)\n",
    "valid_ds = ds.sel(time=valid_period)\n",
    "test_ds = ds.sel(time=test_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that, we can set up all of the rest of the pipeline configuration. This includes the region we're interested in modeling, the input and output variables, and the timescales we'll model with. Most of this code should be pretty self-explanatory, but it's probably worth highlighting the `input_sequence_length` and `output_sequence_length` variables. As we will get into, we'll be training a \"recurrent neural network\" (RNN), which processes variables sequentially and has the ability to store some \"hidden state\" which is able to track information coming in from past inputs. The reason that we specify different input/output sequence lengths is because we know that snowpack has a long-term dependence on temperature and precipitation. So, we define a much longer input sequence lenth than output sequence length to capture this long-term dependence. We set the input to be 360 days to be able to account for roughly a full year of input data, and the output to be 30 so that we predict about a month of snowpack dynamics for any given input.  This asymmetry amounts to letting the model \"spin up\" it's hidden state for the first 330 days and then start to output for the last 30. These are arbitrary choices in our case, which account for some level of knowledge that we have about snow hydrology, but could be further tuned as \"hyperparameters\". As a last note, we set the `input_overlap` to be the difference between the input and output sequence lengths as a way to take advantage of as much as data as possible in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1670557797268
    },
    "id": "I3CoB3HW8QdX",
    "outputId": "9f7a7817-bfd4-48ca-e22c-adbee29846b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions = 'WNA'\n",
    "input_vars = ['pr',  'tasmax',  'tasmin',  'elevation',  'aspect_cosine']\n",
    "output_vars = ['swe']\n",
    "input_sequence_length = 360\n",
    "output_sequence_length = 30\n",
    "batch_dims={'lat': 30, 'lon': 30}\n",
    "input_overlap={'time': input_sequence_length - output_sequence_length} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything set up, we can use our handy `make_data_pipeline` function to create the pipes for the training and validation datasets. Note how these make use of all of our metadata/hyperparameters from above in a nicely encapsulated way. This could ideally even be taken to other problems where similar datasets are being used, perhaps for something like soil moisture modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipe = make_data_pipeline(\n",
    "    train_ds, regions,\n",
    "    input_vars, output_vars,\n",
    "    input_sequence_length, output_sequence_length,\n",
    "    batch_dims, input_overlap, preload=True\n",
    ")\n",
    "\n",
    "valid_pipe = make_data_pipeline(\n",
    "    valid_ds, regions,\n",
    "    input_vars, output_vars,\n",
    "    input_sequence_length, output_sequence_length,\n",
    "    batch_dims, input_overlap, preload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing the model structure\n",
    "\n",
    "We have finally gotten to the point where we can start developing our model structure. This part is going to be quite concise in terms of the code that we'll use, but behind such a short amout of code are decades of both code and mathematical development. We'll take a brief detour to understand how/why we use the methods we do before moving on.\n",
    "\n",
    "<<! LSTM world here>>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of this background understanding in tow, we can start to tackle the practical problem of building our model. For the most part we can rely on off-the-shelf components, but it's worth seeing how to implement a (very) basic neural network layer in the pytorch framework. To be clear, what follows could be implemented inside of something like the training loop, but [training neural networks is a leaky abstraction](http://karpathy.github.io/2019/04/25/recipe/) and as often as possible, it is better to decouple what your model *does* from how *well* it does it.\n",
    "\n",
    "As we saw, an LSTM network can take an input of dimensions `(batch, timesteps, features)` and output `(batch, timesteps, targets)`. But, it's often the case (including here) where the number of input timesteps won't match the number of target timesteps. From an abstract standpoint this is exactly the same consideration as converting the *features* dimension to a *target* dimension. But unlike situations like language translation where the length of an input and output sequence length may be decoupled, we claim that any change in snowpack can only be a result of the meteorologic conditions from today or the past. As such, we further claim that the current snowpack state is only a function of some history of meteorologic states. This is exactly how we've set up the data loaders!\n",
    "\n",
    "To take advantage of this, and the setup of the standard LSTM module from pytorch we can define the `LSTMOutput` class, which is a neural network \"layer\", that simply truncates the output time length to whatever is specified via the `out_len` variable. This is done in standard python fashion by declaring the class and `__init__` consstructor method, as well as standard pytorch fashion by defining the `forward` method which tells pytorch how to handle the forward application, while the backpropagation can be handled via pytorch's internal machinery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMOutput(nn.Module):\n",
    "    def __init__(self, out_len=1):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # nn.LSTM returns (output, (hn, cn)), so we just\n",
    "        # want to grab the `output`\n",
    "        # Output shape (batch, sequence_length, hidden)\n",
    "        output, _ = x\n",
    "        # Now just grab the last index on the sequence length\n",
    "        # Reshape shape (batch, output_timesteps, hidden)\n",
    "        return output[:, -self.out_len:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our custom layer set up we can start to build our model that will (hopefully) do something useful! In the act of doing this we will be good scientists and put the full model creation workflow into a function that can take even more hyperparameters into consideration. We'll set some defaults here just to get things started. Then, in the `create_lstm_model` function we simply create a new overall model structure by chaining together layers, starting with the pytorch implementation of the LSTM, followed by our `LSTMOtput` layer that select on time, and finally followed by a linear layer to project the dimensionality from the `hidden_size` down to the `output_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1670555328046
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "learning_rate = 1e-4\n",
    "dropout=0.0\n",
    "\n",
    "def create_lstm_model(\n",
    "    input_size, \n",
    "    hidden_size, \n",
    "    output_size, \n",
    "    output_sequence_length,\n",
    "    num_layers, \n",
    "    dropout\n",
    "):\n",
    "    model = nn.Sequential(\n",
    "        nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        ),\n",
    "        LSTMOutput(output_sequence_length),\n",
    "        nn.Linear(in_features=hidden_size, out_features=output_size, bias=False),\n",
    "        nn.LeakyReLU()\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can easily create new models in a programattic way, which makes hyperparameter tuning and reproducibility much easier. We can use this function right away, given all of our other configuration. But, before we can actually train the model there are a couple other pieces that need to be connected. Namcely a loss function and optimizer. These both have many options including those implemented by default via the pytorch library but are generally beyond the scope of this tutorial. We'll just use the standard `Adam` optimizer (with  learning rate hyperparameter defined above) and mean squared error loss here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1670555328046
    }
   },
   "outputs": [],
   "source": [
    "model = create_lstm_model(\n",
    "    len(input_vars), \n",
    "    hidden_size, \n",
    "    len(output_vars), \n",
    "    output_sequence_length, \n",
    "    num_layers, \n",
    "    dropout\n",
    ")\n",
    "model = model.float().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../experiments/tutorial/tutorial.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1670555328046
    }
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fun = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some quick model/data verification\n",
    "\n",
    "Many tutorials would jump straight into training the model now, but from a practical standpoint, it's worth making sure that your data inputs/outputs match up in the way that you expect them to before getting too deep. This can largely be a matter of trial and error in the worst case, but if you are careful and understand everything that happens in your model merely a formality. Starting here we'll first see that our input and output batches contain differences along both the `timesteps` and `features` dimensions. This should come as no surprise, but quantifying it should be a good \"gut check\". Similarly, we can make sure that the output of our model is the same as the target from the dataloader. If this is not the case something is wrong and you will need to go back in the data/model workflow to debug what's going on before you can train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims are: (batch, timesteps, features)\n",
      "torch.Size([232, 360, 5]) torch.Size([232, 30, 1])\n",
      "Model targets match output  True\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_pipe))\n",
    "x = x.to(DEVICE)\n",
    "y = y.to(DEVICE)\n",
    "\n",
    "print('Dims are: (batch, timesteps, features)')\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        'Model targets match output ',\n",
    "        model(x).shape == y.shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, opt, loss_fun, device=DEVICE):\n",
    "    avg_loss = 0.0\n",
    "    for i, (x, y) in (bar := tqdm(enumerate(loader))):\n",
    "        # First check that there are valid samples\n",
    "        if not len(x): continue\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fun(yhat, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        avg_loss += loss.cpu().detach().float().numpy()\n",
    "        bar.set_description(f'Training loss: {loss:.2e}')\n",
    "    bar.container.close()\n",
    "    return avg_loss / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, loader, opt, loss_fun, device=DEVICE):    \n",
    "    avg_loss = 0.0\n",
    "    for i, (x, y) in (bar := tqdm(enumerate(loader))):\n",
    "        # First check that there are valid samples\n",
    "        if not len(x): continue\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        model.eval()\n",
    "        opt.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            yhat = model(x)\n",
    "        loss = loss_fun(yhat, y)\n",
    "        avg_loss += loss.cpu().float().numpy()\n",
    "        bar.set_description(f'Validation loss: {loss:.2e}')\n",
    "    bar.container.close()\n",
    "    return avg_loss / i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "max_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a81168e9f84da0bdb3681fcdb36759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13269c65eb464d48a08a3a6e48e0afb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m (bar \u001b[38;5;241m:=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(max_epochs))):\n\u001b[0;32m----> 2\u001b[0m     vl \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_pipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     tl \u001b[38;5;241m=\u001b[39m train_epoch(model, train_pipe, opt, loss_fun)\n\u001b[1;32m      4\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(tl), valid_loss\u001b[38;5;241m.\u001b[39mappend(vl)\n",
      "Cell \u001b[0;32mIn [12], line 13\u001b[0m, in \u001b[0;36mvalid_epoch\u001b[0;34m(model, loader, opt, loss_fun, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         yhat \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fun(yhat, y)\n\u001b[0;32m---> 13\u001b[0m     avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     14\u001b[0m     bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m bar\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in (bar := tqdm(range(max_epochs))):\n",
    "    vl = valid_epoch(model, valid_pipe, opt, loss_fun)\n",
    "    tl = train_epoch(model, train_pipe, opt, loss_fun)\n",
    "    train_loss.append(tl), valid_loss.append(vl)\n",
    "    bar.set_description(f'Train loss: {tl:0.1e}, valid loss: {vl:0.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss[1:], label='Train')\n",
    "plt.plot(valid_loss[1:], label='Valid')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.semilogy()\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A very light introduction to MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = {\n",
    "    \"data_config\": {\n",
    "        # Note: using `start`/`stop` attributes so we save a tuple\n",
    "        \"train_period\": (train_period.start, train_period.stop),\n",
    "        \"valid_period\": (valid_period.start, valid_period.stop),\n",
    "        \"test_period\": (test_period.start, test_period.stop),\n",
    "        \"regions\": regions,\n",
    "        \"input_vars\": input_vars,\n",
    "        \"output_vars\": output_vars,\n",
    "        \"input_sequence_length\": input_sequence_length,\n",
    "        \"output_sequence_length\": output_sequence_length,\n",
    "        \"batch_dims\": batch_dims,\n",
    "        \"input_overlap\": input_overlap\n",
    "    },\n",
    "    \"model_config\": {\n",
    "        \"input_size\": len(input_vars),\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"output_size\": len(output_vars),\n",
    "        \"output_sequence_length\": output_sequence_length,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"dropout\": dropout\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment(config, output_dir, name, model=None):\n",
    "    outfile = f\"{output_dir}/{name}.yml\"\n",
    "    if model:\n",
    "        config[\"weights_file\"] = f\"{output_dir}/{name}.pt\"\n",
    "        torch.save(model.state_dict(), f\"{output_dir}/{name}.pt\")\n",
    "    with open(outfile, \"w\") as f:\n",
    "        yaml.dump(config, f)\n",
    "    return outfile\n",
    "\n",
    "\n",
    "def load_experiment(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.load(f)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = save_experiment(\n",
    "    config=experiment_config, \n",
    "    output_dir=\"../experiments/tutorial\", \n",
    "    name=\"tutorial\", \n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = load_experiment(f)\n",
    "experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = create_lstm_model(**experiment_config['model_config'])\n",
    "loaded_model.load_state_dict(torch.load(experiment_config['weights_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
