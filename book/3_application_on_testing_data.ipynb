{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb35da6-0e5a-40d1-929f-b9416e21944f",
   "metadata": {},
   "source": [
    "# Tutorial 3: Evaluating the trained model on the test data\n",
    "\n",
    "### Outline\n",
    "\n",
    "* Imports, including library code from previous steps\n",
    "* Loading the trained model using hyperparameters and weights file\n",
    "* Setting up the datapipe for the test data\n",
    "* Some functions for \"undoing/inverting\" the ETL pipeline (aka recovering spatiotemporal relations)\n",
    "* Running the trained model in eval mode\n",
    "* Some basic metrics and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8867f-9e85-45c3-b014-519f54539de9",
   "metadata": {
    "gather": {
     "logged": 1670556560147
    },
    "id": "EyDDFpFn7z9o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "import time\n",
    "import torch\n",
    "import torchdata\n",
    "import intake\n",
    "import regionmask\n",
    "import xbatcher\n",
    "import zen3geo as zg\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.autonotebook import tqdm\n",
    "from functools import partial\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from torchdata.datapipes import functional_datapipe\n",
    "from torchdata.datapipes.iter import IterDataPipe\n",
    "from torchdata.datapipes.utils import StreamWrapper\n",
    "from torchdata.dataloader2 import DataLoader2\n",
    "from torch.utils.data import DataLoader\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14cec91-5d41-4263-b263-072001048cd9",
   "metadata": {
    "gather": {
     "logged": 1670555404774
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dask.config.set(**{'array.slicing.split_large_chunks': False})\n",
    "#cluster = LocalCluster(\n",
    "#    n_workers=24,\n",
    "#    threads_per_worker=1,\n",
    "#    memory_limit='6GB',\n",
    "#    dashboard_address=':2345'\n",
    "#)\n",
    "#client = Client(cluster)\n",
    "#client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2e296-7d43-4774-afdc-6255532369db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:02&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat = intake.open_esm_datastore(\n",
    "  'https://cpdataeuwest.blob.core.windows.net/cp-cmip/version1/catalogs/global-downscaled-cmip6.json'\n",
    ")\n",
    "\n",
    "cat_subset = cat.search(\n",
    "    method=\"GARD-SV\",\n",
    "    source_id=\"CanESM5\",\n",
    "    experiment_id=\"ssp245\",\n",
    "    variable_id=['tasmin', 'tasmax', 'pr'],\n",
    "    timescale='day',\n",
    ")\n",
    "dsets = cat_subset.to_dataset_dict()\n",
    "met_ds = list(dsets.values())[0]#.chunk({'time': 1, 'lat': 48, 'lon': 48})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0449d54-2e77-4891-b3bf-577fab14a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import intake\n",
    "\n",
    "def merge_data():\n",
    "    cat = intake.open_esm_datastore(\n",
    "      'https://cpdataeuwest.blob.core.windows.net/cp-cmip/version1/catalogs/global-downscaled-cmip6.json'\n",
    "    )\n",
    "    \n",
    "    cat_subset = cat.search(\n",
    "        method=\"GARD-SV\",\n",
    "        source_id=\"CanESM5\",\n",
    "        experiment_id=\"ssp245\",\n",
    "        variable_id=['tasmin', 'tasmax', 'pr'],\n",
    "        timescale='day',\n",
    "    )\n",
    "    dsets = cat_subset.to_dataset_dict()\n",
    "    met_ds = list(dsets.values())[0]\n",
    "    met_ds['lon'] = met_ds['lon'] % 360\n",
    "    mask = xr.open_dataset('https://esiptutorial.blob.core.windows.net/eraswe/mask_10k_household.zarr', engine='zarr')\n",
    "    terrain = xr.open_dataset('https://esiptutorial.blob.core.windows.net/eraswe/processed_slope_aspect_elevation.zarr', engine='zarr')\n",
    "    #terrain['lon'] = terrain['lon'] + 180\n",
    "    met_ds['mask'] = mask['sd'].rename({'latitude': 'lat', 'longitude': 'lon'})\n",
    "    met_ds = xr.merge([met_ds, terrain])\n",
    "    met_ds['mask'] = np.logical_and(~np.isnan(met_ds['elevation']), met_ds['mask']>0 ).astype(int)\n",
    "    #met_ds['lon'] = met_ds['lon'] + 360\n",
    "    return met_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ebc29-5836-4d42-938f-bb07293525d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetPipe(IterDataPipe):\n",
    "    def __init__(self, ds):\n",
    "        super().__init__()\n",
    "        self.ds = ds\n",
    "        \n",
    "    def __iter__(self):\n",
    "        yield self.ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c69ec-12e0-45d1-b6d7-cb70c98d2829",
   "metadata": {
    "gather": {
     "logged": 1670555464985
    },
    "id": "ohF8jFzw8OdG"
   },
   "outputs": [],
   "source": [
    "#@functional_datapipe(\"subset_regions\")\n",
    "class RegionalSubsetterPipe(IterDataPipe):\n",
    "        \n",
    "    def __init__(self, ds, selected_regions, repeat_region=10, preload=True):\n",
    "        self.current_region = None\n",
    "        self.ds = ds\n",
    "        self.repeat_region = repeat_region\n",
    "        self.selected_regions = [s for s in selected_regions \n",
    "                                 for _ in range(self.repeat_region)]\n",
    "        self.preload = preload\n",
    "        \n",
    "    def select_region(self, region): \n",
    "        regions = regionmask.defined_regions.ar6.land\n",
    "        region_id_mask = regions.mask(ds['lon'], ds['lat'])\n",
    "        reg = np.unique(region_id_mask.values)\n",
    "        reg = reg[~np.isnan(reg)]\n",
    "        region_abbrevs = np.array(regions[reg].abbrevs)\n",
    "        region_names = np.array(regions[reg].names)\n",
    "        \n",
    "        selection_mask = 0.0 * region_id_mask.copy()\n",
    "        region_idx = np.argwhere(region_abbrevs == region)[0][0]\n",
    "        region_mask = (region_id_mask == region_idx).astype(int)\n",
    "        return self.ds.where(region_mask, drop=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for region in self.selected_regions:\n",
    "            if region != self.current_region:\n",
    "                self.selected_ds = self.select_region(region)\n",
    "                if self.preload:\n",
    "                    self.selected_ds = self.selected_ds.load()\n",
    "            self.current_region = region\n",
    "            yield self.selected_ds\n",
    "\n",
    "\n",
    "def filter_batch(batch):\n",
    "    return batch.where(batch['mask']>0, drop=True)\n",
    "\n",
    "\n",
    "def transform_batch(batch):\n",
    "    scale_means = xr.Dataset()\n",
    "    scale_means['mask'] = 0.0\n",
    "    scale_means['swe'] = 0.0\n",
    "    scale_means['pr'] = 0.00\n",
    "    scale_means['tasmax'] = 295.0\n",
    "    scale_means['tasmin'] = 280.0\n",
    "    scale_means['elevation'] = 630.0\n",
    "    scale_means['aspect_cosine'] = 0.0\n",
    "    \n",
    "    scale_stds = xr.Dataset()\n",
    "    scale_stds['mask'] = 1.0\n",
    "    scale_stds['swe'] = 3.0\n",
    "    scale_stds['pr'] = (3600*25)/100.0\n",
    "    scale_stds['tasmax'] = 80.0\n",
    "    scale_stds['tasmin'] = 80.0\n",
    "    scale_stds['elevation'] = 830.0\n",
    "    scale_stds['aspect_cosine'] = 1.0\n",
    "    \n",
    "    batch = (batch - scale_means) / scale_stds\n",
    "    return batch\n",
    "\n",
    "\n",
    "def stack_split_convert(\n",
    "    batch, \n",
    "    in_vars, \n",
    "    out_vars, \n",
    "    in_selectors={},\n",
    "    out_selectors={},\n",
    "    device=None,\n",
    "    min_samples=100\n",
    "):\n",
    "    if len(batch['sample']) > min_samples:\n",
    "        x = (batch[in_vars]\n",
    "                 .to_array()\n",
    "                 .transpose('sample', 'time', 'variable')\n",
    "                 .isel(**in_selectors))\n",
    "        x = torch.tensor(x.values).float()\n",
    "        if device:\n",
    "            x = x.to(device)\n",
    "            \n",
    "        if len(out_vars):\n",
    "            y = (batch[out_vars]\n",
    "                      .to_array()\n",
    "                      .transpose('sample', 'time', 'variable')\n",
    "                      .isel(**out_selectors))\n",
    "            y = torch.tensor(y.values).float()\n",
    "            if device:\n",
    "                y = y.to(device)\n",
    "        else: \n",
    "            y = torch.tensor([])\n",
    "    else:\n",
    "        x, y = torch.tensor([]), torch.tensor([])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class LSTMOutput(nn.Module):\n",
    "    def __init__(self, out_len=1):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # A stupid hack to get around the fact that nn.LSTM \n",
    "        # returns (output, (hn, cn))\n",
    "        # Output shape (batch, sequence_length, hidden)\n",
    "        tensor, _ = x\n",
    "        # Now just grab the last index on the sequence lenght\n",
    "        # Reshape shape (batch, hidden)\n",
    "        return tensor[:, -self.out_len:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea370de-94a9-4761-8673-2b6142e5bbc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1670557797268
    },
    "id": "I3CoB3HW8QdX",
    "outputId": "9f7a7817-bfd4-48ca-e22c-adbee29846b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_ds = merge_data().squeeze().sel(lat=slice(17.5, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7246711-bbe9-4b70-8a46-8c32314fc16f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1670557797268
    },
    "id": "I3CoB3HW8QdX",
    "outputId": "9f7a7817-bfd4-48ca-e22c-adbee29846b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_offset=14\n",
    "ds = full_ds.sel(time=slice('2060', '2069')).isel(time=slice(time_offset, None))\n",
    "\n",
    "with ProgressBar():\n",
    "    gcm_pr = (ds['pr'].where(ds['mask'], other=np.nan)\n",
    "              .max(dim='time')\n",
    "              .compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2a4a2-0578-4992-8dc8-c2914dbd8dc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1670557797268
    },
    "id": "I3CoB3HW8QdX",
    "outputId": "9f7a7817-bfd4-48ca-e22c-adbee29846b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_vars = ['pr',  'tasmax',  'tasmin',  'elevation',  'aspect_cosine']\n",
    "out_vars = []\n",
    "varlist = ['mask'] + in_vars + out_vars\n",
    "input_sequence_length = 180  \n",
    "output_sequence_length = 1\n",
    "output_selector = {'time': slice(-output_sequence_length, None)}\n",
    "input_dims={'time': input_sequence_length}\n",
    "batch_dims={'lat': 290, 'lon': 180}\n",
    "input_overlap={'time': 14}\n",
    "           \n",
    "convert = partial(\n",
    "    stack_split_convert, \n",
    "    in_vars=in_vars, \n",
    "    out_vars=out_vars, \n",
    "    out_selectors=output_selector,\n",
    "    device=DEVICE,\n",
    "    min_samples=90,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c713aaa-adda-4d85-99af-9a6730d87881",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DatasetPipe(ds)\n",
    "dp = dp.slice_with_xbatcher(\n",
    "    input_dims=input_dims,\n",
    "    batch_dims=batch_dims,\n",
    "    input_overlap=input_overlap,\n",
    "    preload_batch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a29d2-5a5a-4834-a26a-df98f0b24599",
   "metadata": {
    "gather": {
     "logged": 1670555328046
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.25\n",
    "base_name = f'regional_xen_lstm_h{hidden_size}_d{num_layers}'\n",
    "base_name = f'regional_xna_lstm_h{hidden_size}_d{num_layers}'\n",
    "\n",
    "model_state = None\n",
    "\n",
    "state_files = sorted(glob(f'../trained_models/{base_name}*.pt'))\n",
    "model_state = torch.load(state_files[-1])\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.LSTM(\n",
    "        input_size=len(in_vars), \n",
    "        hidden_size=hidden_size, \n",
    "        batch_first=True,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    ),\n",
    "    LSTMOutput(output_sequence_length),\n",
    "    nn.Linear(in_features=hidden_size, out_features=1),\n",
    "    nn.SELU()\n",
    ").float()\n",
    "if model_state:\n",
    "    model.load_state_dict(model_state)\n",
    "model = model.to(DEVICE)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eecf94-5d9f-4add-a467-b1a0524725e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba5ced-48ac-4dba-990b-e607f2cd0ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, sample in tqdm(enumerate(dp)):\n",
    "    #if i <= 282: continue\n",
    "    print(sample['time'].values[-1], \n",
    "          sample['lat'].min().values[()],\n",
    "          sample['lon'].min().values[()], )\n",
    "    t = sample['time'].isel(time=-1)\n",
    "    if not t.dt.month.values[()] in [12, 1, 2]: continue\n",
    "    print('filtering...')\n",
    "    filtered = filter_batch(sample)\n",
    "    print('transforming...')\n",
    "    transformed = transform_batch(filtered)\n",
    "    print('converting...')\n",
    "    x, y = convert(transformed)\n",
    "    if not len(x):\n",
    "        print()\n",
    "        continue\n",
    "    print('running_model...')\n",
    "    with torch.no_grad():\n",
    "        yhat = model(x).cpu().numpy().squeeze()\n",
    "    torch.cuda.empty_cache()\n",
    "    print('reassembling_prediction...')\n",
    "    pred = np.nan * xr.zeros_like(sample['mask'])\n",
    "    pred.loc[sample['mask'] == 1] = yhat\n",
    "    pred = pred.unstack()\n",
    "    pred['time'] = sample['time'].isel(time=-1)\n",
    "    pred.name = 'swe'\n",
    "    all_pred.append(pred)\n",
    "    print('writing chunk...')\n",
    "    pred.to_netcdf(f'../full_chunks/ap_{time_offset}_{i}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34147245-5a1e-43ce-af6f-88be266463a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
