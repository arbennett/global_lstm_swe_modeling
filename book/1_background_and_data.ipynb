{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Background and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3PqH0Sr7myM",
    "outputId": "425949ac-3264-4144-d12d-220737c47422",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -q zarr torchdata zen3geo dask[distributed] intake xarray fsspec aiohttp regionmask --upgrade\n",
    "#!pip install -q git+https://github.com/carbonplan/cmip6-downscaling.git@1.0\n",
    "#!pip install -q git+https://github.com/xarray-contrib/xbatcher.git@463546e7739e68b10f1ae456fb910a1628de1e5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1670556560147
    },
    "id": "EyDDFpFn7z9o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "import time\n",
    "import torch\n",
    "import torchdata\n",
    "import intake\n",
    "import regionmask\n",
    "import xbatcher\n",
    "import zen3geo as zg\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.autonotebook import tqdm\n",
    "from functools import partial\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from torchdata.datapipes import functional_datapipe\n",
    "from torchdata.datapipes.iter import IterDataPipe\n",
    "from torchdata.datapipes.utils import StreamWrapper\n",
    "from torchdata.dataloader2 import DataLoader2\n",
    "from torch.utils.data import DataLoader\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1670555464985
    },
    "id": "ohF8jFzw8OdG"
   },
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    era5_daily_cat = intake.open_esm_datastore(\n",
    "        'https://cpdataeuwest.blob.core.windows.net/cp-cmip/training/ERA5-daily-azure.json'\n",
    "    )\n",
    "    met_files = sorted(list(era5_daily_cat.search(cf_variable_name='tasmax').df['zstore']))\n",
    "    years = np.arange(1985, 2015)\n",
    "    swe_files = [f'https://esiptutorial.blob.core.windows.net/eraswe/era5_raw_swe/era5_raw_swe_{year}.zarr'\n",
    "             for year in years]\n",
    "    swe_ds = xr.open_mfdataset(swe_files, engine='zarr')\n",
    "    daily_swe = swe_ds.resample(time='1D').mean().rename({'latitude': 'lat', 'longitude': 'lon'})\n",
    "    met_ds = xr.open_mfdataset(met_files,  engine='zarr')#.sel(time=swe_data['time'])\n",
    "    met_ds = met_ds.sel(time=slice(daily_swe['time'].min(), daily_swe['time'].max()))\n",
    "    met_ds['swe'] = daily_swe['sd']\n",
    "    mask = xr.open_dataset('https://esiptutorial.blob.core.windows.net/eraswe/mask_10k_household.zarr', engine='zarr')\n",
    "    terrain = xr.open_dataset('https://esiptutorial.blob.core.windows.net/eraswe/processed_slope_aspect_elevation.zarr', engine='zarr')\n",
    "    met_ds['mask'] = mask['sd'].rename({'latitude': 'lat', 'longitude': 'lon'})\n",
    "    met_ds = xr.merge([met_ds, terrain])\n",
    "    met_ds['mask'] = np.logical_and(~np.isnan(met_ds['elevation']), met_ds['mask']>0 ).astype(int)\n",
    "    return met_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1670557797268
    },
    "id": "I3CoB3HW8QdX",
    "outputId": "9f7a7817-bfd4-48ca-e22c-adbee29846b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = merge_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to `torchdata.datapipes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNumbersPipe(IterDataPipe):\n",
    "    \n",
    "    def __init__(self, sample_shape, number_samples):\n",
    "        super().__init__()\n",
    "        self.sample_shape = sample_shape\n",
    "        self.number_samples = number_samples\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for _ in range(number_samples):\n",
    "            yield torch.randn(self.sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = RandomNumbersPipe(sample_shape=(5,2,), number_samples=3)\n",
    "for sample in randoms:\n",
    "    print(f'Shape: {sample.shape}, Mean: {torch.mean(sample)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(x):\n",
    "    return x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = RandomNumbersPipe(sample_shape=(5,2,), number_samples=3)\n",
    "tranposeds = randoms.map(transpose)\n",
    "\n",
    "for sample in randoms:\n",
    "    print(f'Shape: {sample.shape}, Mean: {torch.mean(sample)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The extract-transform-load (ETL) pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1670555464985
    },
    "id": "ohF8jFzw8OdG"
   },
   "outputs": [],
   "source": [
    "class RegionalSubsetterPipe(IterDataPipe):\n",
    "        \n",
    "    def __init__(self, ds, selected_regions, repeat_region=10, preload=True):\n",
    "        self.current_region = None\n",
    "        self.ds = ds\n",
    "        self.repeat_region = repeat_region\n",
    "        self.selected_regions = [s for s in selected_regions \n",
    "                                 for _ in range(self.repeat_region)]\n",
    "        self.preload = preload\n",
    "        \n",
    "    def select_region(self, region): \n",
    "        regions = regionmask.defined_regions.ar6.land\n",
    "        region_id_mask = regions.mask(ds['lon'], ds['lat'])\n",
    "        reg = np.unique(region_id_mask.values)\n",
    "        reg = reg[~np.isnan(reg)]\n",
    "        region_abbrevs = np.array(regions[reg].abbrevs)\n",
    "        region_names = np.array(regions[reg].names)\n",
    "        \n",
    "        selection_mask = 0.0 * region_id_mask.copy()\n",
    "        region_idx = np.argwhere(region_abbrevs == region)[0][0]\n",
    "        region_mask = (region_id_mask == region_idx).astype(int)\n",
    "        return self.ds.where(region_mask, drop=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for region in self.selected_regions:\n",
    "            if region != self.current_region:\n",
    "                self.selected_ds = self.select_region(region)\n",
    "                if self.preload:\n",
    "                    self.selected_ds = self.selected_ds.load()\n",
    "            self.current_region = region\n",
    "            yield self.selected_ds\n",
    "\n",
    "def filter_batch(batch):\n",
    "    return batch.where(batch['mask']>0, drop=True)\n",
    "\n",
    "\n",
    "def transform_batch(batch):\n",
    "    scale_means = xr.Dataset()\n",
    "    scale_means['mask'] = 0.0\n",
    "    scale_means['swe'] = 0.0\n",
    "    scale_means['pr'] = 0.00\n",
    "    scale_means['tasmax'] = 295.0\n",
    "    scale_means['tasmin'] = 280.0\n",
    "    scale_means['elevation'] = 630.0\n",
    "    scale_means['aspect_cosine'] = 0.0\n",
    "    \n",
    "    scale_stds = xr.Dataset()\n",
    "    scale_stds['mask'] = 1.0\n",
    "    scale_stds['swe'] = 3.0\n",
    "    scale_stds['pr'] = 1/100.0\n",
    "    scale_stds['tasmax'] = 80.0\n",
    "    scale_stds['tasmin'] = 80.0\n",
    "    scale_stds['elevation'] = 830.0\n",
    "    scale_stds['aspect_cosine'] = 1.0\n",
    "    \n",
    "    batch = (batch - scale_means) / scale_stds\n",
    "    return batch\n",
    "\n",
    "def stack_split_convert(\n",
    "    batch, \n",
    "    in_vars, \n",
    "    out_vars, \n",
    "    in_selectors={},\n",
    "    out_selectors={},\n",
    "    device=None,\n",
    "    min_samples=200\n",
    "):\n",
    "    if len(batch['sample']) > min_samples:\n",
    "        x = (batch[in_vars]\n",
    "                 .to_array()\n",
    "                 .transpose('sample', 'time', 'variable')\n",
    "                 .isel(**in_selectors))\n",
    "        y = (batch[out_vars]\n",
    "                  .to_array()\n",
    "                  .transpose('sample', 'time', 'variable')\n",
    "                  .isel(**out_selectors))\n",
    "        x = torch.tensor(x.values).float()\n",
    "        y = torch.tensor(y.values).float()\n",
    "        if device:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "    else:\n",
    "        x, y = torch.tensor([]), torch.tensor([])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1670557797268
    },
    "id": "I3CoB3HW8QdX",
    "outputId": "9f7a7817-bfd4-48ca-e22c-adbee29846b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_vars = ['pr',  'tasmax',  'tasmin',  'elevation',  'aspect_cosine']\n",
    "out_vars = ['swe']\n",
    "varlist = ['mask'] + in_vars + out_vars\n",
    "input_sequence_length = 180  \n",
    "output_sequence_length = 1\n",
    "output_selector = {'time': slice(-output_sequence_length, None)}\n",
    "input_dims={'time': input_sequence_length}\n",
    "batch_dims={'lat': 30, 'lon': 30}\n",
    "input_overlap={'time': 45}\n",
    "           \n",
    "convert = partial(\n",
    "    stack_split_convert, \n",
    "    in_vars=in_vars, \n",
    "    out_vars=out_vars, \n",
    "    out_selectors=output_selector,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    pr = (ds['pr']\n",
    "          .where(ds['mask'], other=np.nan)\n",
    "          .mean(dim='time')\n",
    "          .compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['EEU']\n",
    "#regions =      ['NWN', 'NEN', 'WCE','TIB']# 'RAR', 'TIB', 'WCA']\n",
    "dp = RegionalSubsetterPipe(\n",
    "    ds[varlist].sel(time=slice('1990', '1999')).astype(np.float32),\n",
    "    selected_regions=regions,\n",
    "    repeat_region=1,\n",
    ")\n",
    "\n",
    "eeu = next(iter(dp))\n",
    "\n",
    "eeu.isel(time=100)['tasmax'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['CNA', 'WNA', 'ENA', 'EEU', 'WSB', 'NEU']\n",
    "#regions =      ['NWN', 'NEN', 'WCE','TIB']# 'RAR', 'TIB', 'WCA']\n",
    "dp = RegionalSubsetterPipe(\n",
    "    ds[varlist].sel(time=slice('1985', '2015')).astype(np.float32),\n",
    "    selected_regions=regions,\n",
    "    repeat_region=3,\n",
    ")\n",
    "dp = dp.slice_with_xbatcher(\n",
    "    input_dims=input_dims,\n",
    "    batch_dims=batch_dims,\n",
    "    input_overlap=input_overlap,\n",
    "    preload_batch=False\n",
    ")\n",
    "dp = dp.map(filter_batch)\n",
    "dp = dp.map(transform_batch)\n",
    "dp = dp.map(convert)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
